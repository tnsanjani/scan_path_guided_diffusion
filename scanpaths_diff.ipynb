{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import utils\n",
    "import collections\n",
    "import re\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import types\n",
    "from collections import defaultdict\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def create_images_360(video_dir= '/Users/nagasaithadishetty/Desktop/WEB360/videos', image_size=(2048, 1024), allowed_serials=None):\n",
    "    for video in sorted(os.listdir(video_dir)):\n",
    "        match = re.compile(r'^(\\d{6})\\.mp4$').match(video)\n",
    "        if not match:\n",
    "            continue\n",
    "        serial_number = match.group(1)\n",
    "        output_dir = os.path.join(video_dir,\"Frames_2\", f\"{serial_number}\")\n",
    "        if os.path.exists(output_dir):\n",
    "            continue\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        video_path = os.path.join(video_dir, video)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(f\"* Processing '{video}' — {frame_count} frames\")\n",
    "        for i in range(frame_count):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            frame = cv2.resize(frame, image_size, interpolation=cv2.INTER_AREA)\n",
    "            image_path = os.path.join(output_dir, f\"{i+1}.png\")\n",
    "            cv2.imwrite(image_path, frame)\n",
    "        cap.release()\n",
    "        print(f\"Created {frame_count} frames in '{output_dir}'\\n\")\n",
    "\n",
    "class coordiantes_3d():\n",
    "    def __init__(self, mini_batch_images, transform=None):\n",
    "        self.mini_batch_images = mini_batch_images\n",
    "        self.transform = transform\n",
    "        self.utils = types.SimpleNamespace()\n",
    "        self.utils.image_size = (128, 256)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mini_batch_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.mini_batch_images[idx][0]\n",
    "        scanpaths = self.mini_batch_images[idx][1]\n",
    "        self.utils.image_size = (128, 256)\n",
    "\n",
    "        print(f\"Processing image: {image_path} with scanpaths: {scanpaths}\")\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (4096, 2048), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        original_h, original_w, _ = image.shape\n",
    "        ratio_w = original_w / self.utils.image_size[1]\n",
    "        ratio_h = original_h / self.utils.image_size[0]\n",
    "        image = (cv2.resize(image, (self.utils.image_size[1], self.utils.image_size[0]), interpolation=cv2.INTER_AREA)).astype(np.float32) / 255.0\n",
    "\n",
    "        images = []\n",
    "        scanpaths_3d = []\n",
    "        scanpaths_original = []\n",
    "\n",
    "        for scanpath in scanpaths:\n",
    "            flat_scanpath = []\n",
    "            for i in range(0, len(scanpath), 2):\n",
    "                y = scanpath[i + 1]\n",
    "                x = scanpath[i]\n",
    "                flat_scanpath.append(x / ratio_w)\n",
    "                flat_scanpath.append(y / ratio_h)\n",
    "\n",
    "            for i in range(0, len(flat_scanpath), 2):\n",
    "                flat_scanpath[i] = flat_scanpath[i] / self.utils.image_size[1]\n",
    "                flat_scanpath[i] = ((flat_scanpath[i] * 2) - 1) * (np.pi - 1e-2)\n",
    "                flat_scanpath[i + 1] = flat_scanpath[i + 1] / self.utils.image_size[0]\n",
    "                flat_scanpath[i + 1] = ((flat_scanpath[i + 1] * 2) - 1) * (np.pi / 2 - 1e-2)\n",
    "\n",
    "            three_coord = []\n",
    "            for i in range(0, len(flat_scanpath), 2):\n",
    "                lon = flat_scanpath[i]\n",
    "                lat = flat_scanpath[i + 1]\n",
    "                x = np.cos(lat) * np.cos(lon)\n",
    "                y = np.cos(lat) * np.sin(lon)\n",
    "                z = np.sin(lat)\n",
    "                three_coord.extend([x, y, z])\n",
    "\n",
    "            images.append(self.transform(image) if self.transform else torch.tensor(image).permute(2, 0, 1))\n",
    "            scanpaths_3d.append(torch.FloatTensor(three_coord))\n",
    "            scanpaths_original.append(torch.FloatTensor(flat_scanpath))\n",
    "        return images, scanpaths_3d, scanpaths_original\n",
    "\n",
    "create_images_360(video_dir= '/Users/nagasaithadishetty/Desktop/WEB360/videos', image_size=(2048, 1024), allowed_serials=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a431d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import types\n",
    "import re\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "#remving outliers and interpolating them for consistent scanpaths\n",
    "\n",
    "@staticmethod\n",
    "def great_circle_distance(phi1, lambda1, phi2, lambda2):\n",
    "    delta_lambda = np.abs(lambda1 - lambda2)\n",
    "    K = (np.sin(np.radians(phi1)) * np.sin(np.radians(phi2))) + \\\n",
    "        (np.cos(np.radians(phi1)) * np.cos(np.radians(phi2)) * np.cos(np.radians(delta_lambda)))\n",
    "    return np.arccos(np.clip(K, -1, 1))  \n",
    "\n",
    "class ScanpathData360:\n",
    "    def __init__(self, dataset_root, scan_path_directory):\n",
    "        self.dataset_root = dataset_root\n",
    "        self.scan_path_directory = scan_path_directory\n",
    "        self.images = []\n",
    "        self.image_scanpath_pairs = []\n",
    "        self.image_and_scanpath_dict = defaultdict(dict)\n",
    "        self.load_dataset()\n",
    "        self.cleaned = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    def latlon_to_unitvec(self, lat, lon):\n",
    "        lat_rad = np.radians(lat)\n",
    "        lon_rad = np.radians(lon)\n",
    "        x = np.cos(lat_rad) * np.cos(lon_rad)\n",
    "        y = np.cos(lat_rad) * np.sin(lon_rad)\n",
    "        z = np.sin(lat_rad)\n",
    "        return np.array([x, y, z])\n",
    "\n",
    "    def unitvec_to_latlon(self, vec):\n",
    "        x, y, z = vec\n",
    "        lat = np.degrees(np.arcsin(z))  \n",
    "        lon = np.degrees(np.arctan2(y, x)) \n",
    "        return (lat, lon)\n",
    "\n",
    "    def slerp(self, q1, q2, t, tm):\n",
    "        dot = np.dot(q1, q2)\n",
    "        dot = np.clip(dot, -1.0, 1.0)\n",
    "        if dot > 0.9995:\n",
    "            result = q1 + (t / tm) * (q2 - q1)\n",
    "            return result / np.linalg.norm(result)\n",
    "        theta_0 = np.arccos(dot) \n",
    "        sin_theta_0 = np.sin(theta_0)\n",
    "        theta = theta_0 * (t / tm)\n",
    "        sin_theta = np.sin(theta)\n",
    "\n",
    "        s1 = np.sin(theta_0 - theta) / sin_theta_0\n",
    "        s2 = sin_theta / sin_theta_0\n",
    "        return (s1 * q1) + (s2 * q2)\n",
    "\n",
    "    def remove_outliers(self, scanpath, threshold_factor=2.5):\n",
    "        if len(scanpath) < 2:\n",
    "            return scanpath, []\n",
    "\n",
    "        distances = [self.great_circle_distance(*scanpath[i], *scanpath[i - 1]) for i in range(1, len(scanpath))]\n",
    "        mean_dist = np.mean(distances)\n",
    "        std_dist = np.std(distances)\n",
    "        spatial_threshold = mean_dist + threshold_factor * std_dist\n",
    "\n",
    "        spatial_outliers = {i for i in range(1, len(scanpath)) if distances[i - 1] > spatial_threshold}\n",
    "        cleaned_scanpath = [pt for idx, pt in enumerate(scanpath) if idx not in spatial_outliers]\n",
    "\n",
    "        return cleaned_scanpath, sorted(spatial_outliers)\n",
    "\n",
    "    def load_dataset(self):\n",
    "        video_count = 0\n",
    "        self.images = []\n",
    "        self.image_scanpath_pairs = []\n",
    "        self.image_and_scanpath_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "        for video in sorted(os.listdir(self.dataset_root)):\n",
    "            video_frames_dir = os.path.join(self.dataset_root, video)\n",
    "            csv_path = os.path.join(self.scan_path_directory, f\"{video}.csv\")\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"CSV missing for video {video}, skipping\")\n",
    "                continue\n",
    "            gaze_df = pd.read_csv(csv_path)\n",
    "            gaze_mapping = defaultdict(lambda: defaultdict(list))\n",
    "            for _, row in gaze_df.iterrows():\n",
    "                frame = int(row['frame'])\n",
    "                spid = int(row['scanpath_id'])\n",
    "                gaze_mapping[frame][spid].append((row['y'], row['x']))\n",
    "\n",
    "            frame_files = []\n",
    "            for img_file in os.listdir(video_frames_dir):\n",
    "                img_match = re.match(r'(\\d+)\\.png$', img_file)\n",
    "                if not img_match:\n",
    "                    continue\n",
    "                frame_num = int(img_match.group(1))\n",
    "                img_path = os.path.join(video_frames_dir, img_file)\n",
    "                frame_files.append((frame_num, img_path))\n",
    "\n",
    "            frame_files.sort(key=lambda x: x[0])\n",
    "\n",
    "            total_scanpaths = 0\n",
    "            for frame, img_path in frame_files:\n",
    "                self.images.append(img_path)\n",
    "                gaze_points_per_scanid = gaze_mapping.get(frame, {})\n",
    "                self.image_scanpath_pairs.append((img_path, gaze_points_per_scanid))\n",
    "                self.image_and_scanpath_dict[video][frame] = gaze_points_per_scanid\n",
    "\n",
    "                num_scanpaths = len(gaze_points_per_scanid)\n",
    "                total_scanpaths += num_scanpaths\n",
    "            video_count += 1\n",
    "            if video_count >= 2: \n",
    "                break\n",
    "        return self.image_and_scanpath_dict\n",
    "\n",
    "    def interpolate_only_outliers(self, original_scanpath, removed_indices):\n",
    "        if not removed_indices:\n",
    "            return list(original_scanpath)\n",
    "\n",
    "        n = len(original_scanpath)\n",
    "        interpolated_scanpath = list(original_scanpath) \n",
    "        removed_set = set(removed_indices)\n",
    "\n",
    "        for idx in sorted(removed_indices):\n",
    "            prev_idx = idx - 1\n",
    "            while prev_idx >= 0 and prev_idx in removed_set:\n",
    "                prev_idx -= 1\n",
    "\n",
    "            next_idx = idx + 1\n",
    "            while next_idx < n and next_idx in removed_set:\n",
    "                next_idx += 1\n",
    "\n",
    "            if prev_idx >= 0 and next_idx < n:\n",
    "                p0 = self.latlon_to_unitvec(*original_scanpath[prev_idx])\n",
    "                p1 = self.latlon_to_unitvec(*original_scanpath[next_idx])\n",
    "                t = (idx - prev_idx) / (next_idx - prev_idx)\n",
    "                interp_vec = self.slerp(p0, p1, t, 1)\n",
    "                interp_vec /= np.linalg.norm(interp_vec)\n",
    "                interpolated_scanpath[idx] = self.unitvec_to_latlon(interp_vec)\n",
    "\n",
    "            elif prev_idx < 0 and next_idx < n:\n",
    "                interpolated_scanpath[idx] = original_scanpath[next_idx]\n",
    "\n",
    "            elif prev_idx >= 0 and next_idx >= n:\n",
    "                interpolated_scanpath[idx] = original_scanpath[prev_idx]\n",
    "            else:\n",
    "                interpolated_scanpath[idx] = original_scanpath[idx]\n",
    "        return interpolated_scanpath\n",
    "\n",
    "    def process_scanpaths(self, save_folder=None):\n",
    "        self.cleaned = defaultdict(lambda: defaultdict(dict))\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "        for video in self.image_and_scanpath_dict:\n",
    "            print(f\"Processing Video: {video}\")\n",
    "            video_rows = []\n",
    "\n",
    "            for frame in sorted(self.image_and_scanpath_dict[video]):\n",
    "                scanpaths_dict = self.image_and_scanpath_dict[video][frame]\n",
    "\n",
    "                for scan_id, scanpath in scanpaths_dict.items():\n",
    "                    initial_len = len(scanpath)\n",
    "                    cleaned, removed_indices = self.remove_outliers(scanpath)\n",
    "                    if removed_indices:\n",
    "                        interpolated = self.interpolate_only_outliers(scanpath, removed_indices)\n",
    "                    else:\n",
    "                        interpolated = list(scanpath)\n",
    "\n",
    "                    assert len(interpolated) == initial_len, (f\"Length mismatch for video {video} frame {frame} scan {scan_id}: \"f\"{len(interpolated)} != {initial_len}\")\n",
    "                    self.cleaned[video][frame][scan_id] = interpolated\n",
    "                    for idx, (lat, lon) in enumerate(interpolated):\n",
    "                        video_rows.append([frame, scan_id, idx, lat, lon])\n",
    "\n",
    "            csv_path = os.path.join(save_folder, f\"{video}.csv\")\n",
    "            with open(csv_path, \"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"frame\", \"scanpath_id\", \"point_idx\", \"y\", \"x\"])\n",
    "                writer.writerows(video_rows)\n",
    "data_loader = ScanpathData360(\"/Users/nagasaithadishetty/Desktop/WEB360/videos/Frames\",\"/Users/nagasaithadishetty/Desktop/Diffusion_Research/Multi_Concept_Code/ScanDMM/demo/output\")\n",
    "data_loader.load_dataset()\n",
    "data_loader.process_scanpaths(save_folder=\"/Users/nagasaithadishetty/Desktop/Diffusion_Research/Multi_Concept_Code/ScanDMM/demo/output/interpolated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import types\n",
    "from functools import reduce\n",
    "from fastdtw import fastdtw\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "#clustering and final source scan-path for each image\n",
    "\n",
    "def great_circle_distance_squared(p1, p2):\n",
    "    return great_circle_distance(p1[0], p1[1], p2[0], p2[1])**2\n",
    "\n",
    "def fill_delta_mat_dtw(center, s, delta_mat):\n",
    "    center_len = len(center)\n",
    "    s_len = len(s)\n",
    "    slim = delta_mat[:center_len, :s_len]\n",
    "    for i in range(center_len):\n",
    "        for j in range(s_len):\n",
    "            slim[i, j] = great_circle_distance_squared(center[i], s[j])\n",
    "\n",
    "def squared_DTW(s, t, cost_mat, delta_mat):\n",
    "    s_len = len(s)\n",
    "    t_len = len(t)\n",
    "    \n",
    "    fill_delta_mat_dtw(s, t, delta_mat)\n",
    "    cost_mat[0, 0] = delta_mat[0, 0]\n",
    "    for i in range(1, s_len):\n",
    "        cost_mat[i, 0] = cost_mat[i - 1, 0] + delta_mat[i, 0]\n",
    "\n",
    "    for j in range(1, t_len):\n",
    "        cost_mat[0, j] = cost_mat[0, j - 1] + delta_mat[0, j]\n",
    "\n",
    "    for i in range(1, s_len):\n",
    "        for j in range(1, t_len):\n",
    "            res = min(cost_mat[i - 1, j - 1], cost_mat[i, j - 1], cost_mat[i - 1, j])\n",
    "            cost_mat[i, j] = res + delta_mat[i, j]\n",
    "    return cost_mat[s_len - 1, t_len - 1]\n",
    "\n",
    "def approximate_medoid_index(series, cost_mat, delta_mat):\n",
    "    if len(series) <= 50:\n",
    "        indices = range(len(series))\n",
    "    else:\n",
    "        indices = np.random.choice(range(len(series)), 50, replace=False)\n",
    "\n",
    "    medoid_ind = -1\n",
    "    best_ss = 1e20\n",
    "    for index_candidate in indices:\n",
    "        candidate = series[index_candidate]\n",
    "        ss = sum(map(lambda t: squared_DTW(candidate, t, cost_mat, delta_mat), series))\n",
    "        if (medoid_ind == -1 or ss < best_ss):\n",
    "            best_ss = ss\n",
    "            medoid_ind = index_candidate\n",
    "    return medoid_ind\n",
    "\n",
    "def DBA_update(center, series, cost_mat, path_mat, delta_mat):\n",
    "    options_argmin = [(-1, -1), (0, -1), (-1, 0)]\n",
    "    updated_center = np.zeros(center.shape)\n",
    "    n_elements = np.zeros(center.shape[0], dtype=int)\n",
    "    \n",
    "    center_length = len(center)\n",
    "    for s in series:\n",
    "        s_len = len(s)\n",
    "        fill_delta_mat_dtw(center, s, delta_mat)\n",
    "        cost_mat[0, 0] = delta_mat[0, 0]\n",
    "        path_mat[0, 0] = -1\n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            cost_mat[i, 0] = cost_mat[i - 1, 0] + delta_mat[i, 0]\n",
    "            path_mat[i, 0] = 2 \n",
    "\n",
    "        for j in range(1, s_len):\n",
    "            cost_mat[0, j] = cost_mat[0, j - 1] + delta_mat[0, j]\n",
    "            path_mat[0, j] = 1 \n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            for j in range(1, s_len):\n",
    "                costs = [cost_mat[i - 1, j - 1], cost_mat[i, j - 1], cost_mat[i - 1, j]]\n",
    "                path_mat[i,j] = np.argmin(costs)\n",
    "                cost_mat[i, j] = costs[path_mat[i,j]] + delta_mat[i, j]\n",
    "\n",
    "        i, j = center_length - 1, s_len - 1\n",
    "        while (path_mat[i, j] != -1):\n",
    "            updated_center[i, :] += s[j, :]\n",
    "            n_elements[i] += 1\n",
    "            move = options_argmin[path_mat[i, j]]\n",
    "            i += move[0]\n",
    "            j += move[1]\n",
    "            \n",
    "        updated_center[0, :] += s[0, :]\n",
    "        n_elements[0] += 1\n",
    "\n",
    "    n_elements[n_elements == 0] = 1\n",
    "    return np.divide(updated_center, n_elements[:, np.newaxis])\n",
    "\n",
    "def performDBA(series, max_iterations=300, threshold=0.001):\n",
    "    if not series:\n",
    "        return np.array([])\n",
    "    \n",
    "    n_series = len(series)\n",
    "    max_length = reduce(max, map(len, series))\n",
    "    cost_mat = np.zeros((max_length, max_length))\n",
    "    delta_mat = np.zeros((max_length, max_length))\n",
    "    path_mat = np.zeros((max_length, max_length), dtype=np.int8)\n",
    "\n",
    "    medoid_ind = approximate_medoid_index(series, cost_mat, delta_mat)\n",
    "    center = series[medoid_ind].copy()\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        prev_center = center.copy()\n",
    "        center = DBA_update(center, series, cost_mat, path_mat, delta_mat)\n",
    "\n",
    "        change = np.mean(np.square(center - prev_center))\n",
    "        if change > threshold:\n",
    "            break\n",
    "    return center\n",
    "\n",
    "class ScanpathData360:\n",
    "    def __init__(self, dataset_root, scan_path_directory):\n",
    "        self.dataset_root = dataset_root\n",
    "        self.scan_path_directory = scan_path_directory\n",
    "        self.images = []\n",
    "        self.image_scanpath_pairs = []\n",
    "        self.image_and_scanpath_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "        self.fastdtw_results_by_video_and_frame = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        video_count = 0\n",
    "        for video in sorted(os.listdir(self.dataset_root)):\n",
    "            video_frames_dir = os.path.join(self.dataset_root, video)\n",
    "            csv_path = os.path.join(self.scan_path_directory, f\"{video}.csv\")\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"CSV missing for video {video}, skipping\")\n",
    "                continue\n",
    "            gaze_df = pd.read_csv(csv_path)\n",
    "            gaze_mapping = defaultdict(lambda: defaultdict(list))\n",
    "            for _, row in gaze_df.iterrows():\n",
    "                frame = int(row['frame'])\n",
    "                spid = int(row['scanpath_id'])\n",
    "                gaze_mapping[frame][spid].append((row['y'], row['x']))\n",
    "\n",
    "            frame_files = []\n",
    "            for img_file in os.listdir(video_frames_dir):\n",
    "                img_match = re.match(r'(\\d+)\\.png$', img_file)\n",
    "                if not img_match:\n",
    "                    continue\n",
    "                frame_num = int(img_match.group(1))\n",
    "                img_path = os.path.join(video_frames_dir, img_file)\n",
    "                frame_files.append((frame_num, img_path))\n",
    "\n",
    "            frame_files.sort(key=lambda x: x[0])\n",
    "            total_scanpaths = 0\n",
    "            for frame, img_path in frame_files:\n",
    "                self.images.append(img_path)\n",
    "                gaze_points_per_scanid = gaze_mapping.get(frame, {})\n",
    "                self.image_scanpath_pairs.append((img_path, gaze_points_per_scanid))\n",
    "                self.image_and_scanpath_dict[video][frame] = gaze_points_per_scanid\n",
    "\n",
    "                num_scanpaths = len(gaze_points_per_scanid)\n",
    "                total_scanpaths += num_scanpaths\n",
    "            video_count += 1\n",
    "            if video_count >= 2: \n",
    "                break\n",
    "        print(f\"Loaded {len(self.image_scanpath_pairs)} image-scanpath pairs from {video_count} video(s).\")\n",
    "        return self.image_and_scanpath_dict\n",
    "\n",
    "    def pairwise_scanpath_fastdtw(self, scanpaths_dict, radius=20):\n",
    "        scan_ids = list(scanpaths_dict.keys())\n",
    "        N = len(scan_ids)\n",
    "        fastdtw_matrix = np.zeros((N, N))\n",
    "\n",
    "        def point_distance(p1, p2):\n",
    "            return great_circle_distance(p1[0], p1[1], p2[0], p2[1])\n",
    "\n",
    "        for i in range(N):\n",
    "            sp1 = scanpaths_dict[scan_ids[i]]\n",
    "            for j in range(i + 1, N):\n",
    "                sp2 = scanpaths_dict[scan_ids[j]]\n",
    "                dist, _ = fastdtw(sp1, sp2, radius=radius, dist=point_distance)\n",
    "                fastdtw_matrix[i, j] = dist\n",
    "                fastdtw_matrix[j, i] = dist \n",
    "        return fastdtw_matrix, scan_ids\n",
    "\n",
    "    def compute_all_frames_fastdtw(self, radius=20):\n",
    "        print(\"\\nComputing pairwise FastDTW for all frames...\")\n",
    "        for video in self.image_and_scanpath_dict:\n",
    "            for frame in self.image_and_scanpath_dict[video]:\n",
    "                scanpaths_dict = self.image_and_scanpath_dict[video][frame]\n",
    "                fastdtw_matrix, scan_ids = self.pairwise_scanpath_fastdtw(scanpaths_dict, radius=radius)\n",
    "                self.fastdtw_results_by_video_and_frame[video][frame] = {'matrix': fastdtw_matrix, 'scan_ids': scan_ids}\n",
    "        print(\"FastDTW computation complete.\")\n",
    "        return self.fastdtw_results_by_video_and_frame\n",
    "    \n",
    "    def cluster_and_save_all_frames_1(self, k, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        for video, frame_dict in self.fastdtw_results_by_video_and_frame.items():\n",
    "            video_dir = os.path.join(output_dir, video)\n",
    "            os.makedirs(video_dir, exist_ok=True)\n",
    "            for frame, results in frame_dict.items():\n",
    "                condensed_dist_matrix = squareform(results['matrix'])\n",
    "                scan_ids = results['scan_ids']\n",
    "                Z = linkage(condensed_dist_matrix, method='complete')\n",
    "                cluster_labels = fcluster(Z, t=k, criterion='maxclust')\n",
    "\n",
    "                clusters = defaultdict(list)\n",
    "                for idx, label in enumerate(cluster_labels):\n",
    "                    clusters[label].append(scan_ids[idx])\n",
    "\n",
    "                output_path = os.path.join(video_dir, f\"frame_{frame}.pkl\")\n",
    "                with open(output_path, 'wb') as f:\n",
    "                    pickle.dump({'clusters': clusters, 'linkage_matrix': Z, 'scan_ids': scan_ids}, f)\n",
    "                print(f\"  Saved clustering for {video} frame {frame} to {output_path}\")\n",
    "\n",
    "    def cluster_and_save_all_frames(self, k, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        for video, frame_dict in self.fastdtw_results_by_video_and_frame.items():\n",
    "            video_dir = os.path.join(output_dir, video)\n",
    "            os.makedirs(video_dir, exist_ok=True)\n",
    "            for frame, results in frame_dict.items():\n",
    "                scan_ids = results['scan_ids']\n",
    "                if len(scan_ids) < 2:\n",
    "                    print(f\"  Skipping clustering for {video} frame {frame}: not enough scanpaths ({len(scan_ids)})\")\n",
    "                    continue\n",
    "                condensed_dist_matrix = squareform(results['matrix'])\n",
    "                Z = linkage(condensed_dist_matrix, method='complete')\n",
    "                cluster_labels = fcluster(Z, t=k, criterion='maxclust')\n",
    "\n",
    "                clusters = defaultdict(list)\n",
    "                for idx, label in enumerate(cluster_labels):\n",
    "                    clusters[label].append(scan_ids[idx])\n",
    "\n",
    "                output_path = os.path.join(video_dir, f\"frame_{frame}.pkl\")\n",
    "                with open(output_path, 'wb') as f:\n",
    "                    pickle.dump({'clusters': clusters, 'linkage_matrix': Z, 'scan_ids': scan_ids}, f)\n",
    "                print(f\"  Saved clustering for {video} frame {frame} to {output_path}\")\n",
    "\n",
    "    def display_fastdtw_results(self, k=30, output_dir='clustering_results'):\n",
    "        print(\"\\nDisplaying FastDTW Results and Clustering:\")\n",
    "        for video in sorted(os.listdir(os.path.join(output_dir))):\n",
    "            video_dir = os.path.join(output_dir, video)\n",
    "            if not os.path.isdir(video_dir):\n",
    "                continue\n",
    "            print(f\"Video: {video}\")\n",
    "            for frame_file in sorted(os.listdir(video_dir)):\n",
    "                if frame_file.endswith('.pkl'):\n",
    "                    frame = int(re.match(r'frame_(\\d+)\\.pkl$', frame_file).group(1))\n",
    "                    output_path = os.path.join(video_dir, frame_file)\n",
    "                    \n",
    "                    with open(output_path, 'rb') as f:\n",
    "                        saved_data = pickle.load(f)\n",
    "                    clusters = saved_data['clusters']\n",
    "                    Z = saved_data['linkage_matrix']\n",
    "                    scan_ids = saved_data['scan_ids']\n",
    "\n",
    "                    print(f\"  Frame {frame}:\")\n",
    "                    print(\"\\n=== Scanpaths grouped by cluster ===\")\n",
    "                    for cluster_id, member_scanids in sorted(clusters.items()):\n",
    "                        print(f\"\\nCluster {cluster_id} (size={len(member_scanids)}):\")\n",
    "                        for scan_id in member_scanids:\n",
    "                            print(f\"  Scanpath {scan_id}\")\n",
    "\n",
    "                    plt.figure(figsize=(10, 5))\n",
    "                    dendrogram(Z, truncate_mode='lastp', p=k, leaf_rotation=90., leaf_font_size=12., show_contracted=True)\n",
    "                    plt.title(f\"Hierarchical Clustering Dendrogram for {video}, Frame {frame} (truncated)\")\n",
    "                    plt.xlabel(\"Cluster Index\")\n",
    "                    plt.ylabel(\"Distance\")\n",
    "                    plt.show()\n",
    "\n",
    "    def compute_and_save_final_source_scanpath(self, clustering_dir, output_csv_dir):\n",
    "        for video in sorted(os.listdir(clustering_dir)):\n",
    "            video_dir = os.path.join(clustering_dir, video)\n",
    "            print(f\"\\n--- Processing Video: {video} ---\")\n",
    "            output_dir = os.path.join(output_csv_dir, video)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            frame_files = sorted([f for f in os.listdir(video_dir) if f.endswith('.pkl')],key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "            total_frames = len(frame_files)\n",
    "            frame_csv_saved = 0\n",
    "            for frame_idx, frame_file in enumerate(frame_files):\n",
    "                frame_match = re.match(r'frame_(\\d+)\\.pkl$', frame_file)\n",
    "                if not frame_match:\n",
    "                    continue\n",
    "                frame = int(frame_match.group(1))\n",
    "                try:\n",
    "                    with open(os.path.join(video_dir, frame_file), 'rb') as f:\n",
    "                        data = pickle.load(f)\n",
    "                        clusters = data['clusters']\n",
    "                except Exception as e:\n",
    "                    print(f\"    Frame {frame}: Could not load pickle file. Error: {e}. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                cluster_average_scanpaths = []\n",
    "                for cluster_id, member_scanids in sorted(clusters.items()):\n",
    "                    cluster_scanpaths = [np.array(self.image_and_scanpath_dict[video][frame][spid]) for spid in member_scanids if spid in self.image_and_scanpath_dict[video][frame]]\n",
    "\n",
    "                    if len(cluster_scanpaths) > 1:\n",
    "                        avg_scanpath = performDBA(cluster_scanpaths)\n",
    "                        cluster_average_scanpaths.append(avg_scanpath)\n",
    "                    elif len(cluster_scanpaths) == 1:\n",
    "                        cluster_average_scanpaths.append(cluster_scanpaths[0])\n",
    "\n",
    "                source_scanpath = None\n",
    "                if len(cluster_average_scanpaths) > 1:\n",
    "                    source_scanpath = performDBA(cluster_average_scanpaths)\n",
    "                elif len(cluster_average_scanpaths) == 1:\n",
    "                    source_scanpath = cluster_average_scanpaths[0]\n",
    "\n",
    "                if source_scanpath is not None and source_scanpath.size > 0:\n",
    "                    df_scanpath = pd.DataFrame(source_scanpath, columns=['y', 'x'])\n",
    "                    csv_path = os.path.join(output_dir, f'Frame_{frame}.csv')\n",
    "                    df_scanpath.to_csv(csv_path, index=False)\n",
    "                    frame_csv_saved += 1\n",
    "                    print(f\"    Saved scanpath for Frame {frame} to CSV\")\n",
    "                else:\n",
    "                    print(f\"    Frame {frame_idx+1}/{total_frames} ({frame}): No source scanpath computed.\")\n",
    "\n",
    "dataset_root = \"/Users/nagasaithadishetty/Desktop/WEB360/videos/Frames\"\n",
    "scan_path_directory = \"/Users/nagasaithadishetty/Desktop/Diffusion_Research/Multi_Concept_Code/ScanDMM/demo/output/interpolated\"\n",
    "OUTPUT_DIR = \"/Users/nagasaithadishetty/Desktop/Diffusion_Research/Multi_Concept_Code/ScanDMM/demo/output/clustering_results\"\n",
    "Final_source_DIR = os.path.join(scan_path_directory, 'source_scanpaths')\n",
    "\n",
    "data_loader = ScanpathData360(dataset_root, scan_path_directory)\n",
    "data_loader.load_dataset()\n",
    "data_loader.compute_all_frames_fastdtw(radius=20)\n",
    "data_loader.cluster_and_save_all_frames(k=30, output_dir=OUTPUT_DIR)\n",
    "#data_loader.display_fastdtw_results(k=30, output_dir=OUTPUT_DIR)  \n",
    "data_loader.compute_and_save_final_source_scanpath(clustering_dir=OUTPUT_DIR,output_csv_dir=Final_source_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "source_scanpaths_dir = \"/media/scratch/Trauma_Detection/code/ScanDMM/demo/output/source_scanpaths_csv_initial\"\n",
    "frame_directory = \"/media/scratch/datasets/WEB360/videos_512x1024x100/Frames/\"\n",
    "caption_path = \"/media/scratch/datasets/WEB360/WEB360_360TF_train.csv\"\n",
    "\n",
    "CaptionData = pd.read_csv(caption_path)\n",
    "CaptionData = CaptionData[CaptionData['videoid'].astype(str).isin(os.listdir(frame_directory))]\n",
    "\n",
    "def load_scanpath(scanpath_dir, frame_number):\n",
    "    frame_csv_path = os.path.join(scanpath_dir, f\"Frame_{frame_number}.csv\")\n",
    "    if not os.path.exists(frame_csv_path):\n",
    "        return None, frame_csv_path\n",
    "    df = pd.read_csv(frame_csv_path)\n",
    "    return df[['x', 'y']].values.tolist(), frame_csv_path\n",
    "\n",
    "def plot_single_scanpath_on_image(scanpath, img_path, save_path=None, caption=None, img_height=256, img_width=512):\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    normalized = all(0 <= x <= 1 and 0 <= y <= 1 for x, y in scanpath)\n",
    "    points_x = [(p[0] * img_width if normalized else p[0]) for p in scanpath]\n",
    "    points_y = [(p[1] * img_height if normalized else p[1]) for p in scanpath]\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(scanpath)))\n",
    "\n",
    "    previous_point = None\n",
    "    for idx, (x, y, c) in enumerate(zip(points_x, points_y, colors)):\n",
    "        if previous_point is not None:\n",
    "            if abs(previous_point[0] - x) < (img_width / 2):\n",
    "                ax.plot([previous_point[0], x], [previous_point[1], y], color='blue', linewidth=2, alpha=0.4)\n",
    "            else:\n",
    "                h_diff = (y - previous_point[1]) / 2\n",
    "                if x > previous_point[0]:\n",
    "                    ax.plot([previous_point[0], 0], [previous_point[1], previous_point[1] + h_diff],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                    ax.plot([img_width, x], [previous_point[1] + h_diff, y],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                else:\n",
    "                    ax.plot([previous_point[0], img_width], [previous_point[1], previous_point[1] + h_diff],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                    ax.plot([0, x], [previous_point[1] + h_diff, y],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "        previous_point = (x, y)\n",
    "        ax.plot(x, y, marker='o', markersize=8, color=c, alpha=0.9)\n",
    "        ax.text(x + 4, y - 4, str(idx + 1), color='yellow', fontsize=9)\n",
    "    plt.figtext(0.5, 0.01, f\"📜 {caption}\", wrap=True, ha='center', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def frame_with_scanpath(source_scanpaths_dir, frame_directory, caption_df):\n",
    "    video_data={}\n",
    "    for video_id in sorted(os.listdir(frame_directory)):\n",
    "        video_data[video_id] =[]\n",
    "        video_frame_dir = os.path.join(frame_directory, video_id)\n",
    "        scanpath_video_dir = os.path.join(source_scanpaths_dir, video_id)\n",
    "        caption_row = caption_df[caption_df['videoid'].astype(str) == video_id]\n",
    "        caption_text = caption_row['name'].values[0] if not caption_row.empty else None\n",
    "\n",
    "        print(f\"\\n🎞️ Video: {video_id}\")\n",
    "        frame_files = sorted([f for f in os.listdir(video_frame_dir) if f.lower().endswith('.png')])\n",
    "        for frame_file in frame_files:\n",
    "            frame_number = int(re.search(r'frame_(\\d+)', frame_file).group(1).lstrip('0') or '0')\n",
    "            print(f\"  Frame: {frame_file} (Number: {frame_number})\")\n",
    "            image_path = os.path.join(video_frame_dir, frame_file)\n",
    "            scanpath, csv_path = load_scanpath(scanpath_video_dir, frame_number)\n",
    "            print(f\"  Frame Path : {image_path};  Scanpath CSV: {csv_path}\")\n",
    "            if scanpath is None:\n",
    "                continue\n",
    "            #plot_single_scanpath_on_image(scanpath, image_path, caption=caption_text)\n",
    "            video_data[video_id].append({\"frame_file\": frame_file,\"frame_number\": frame_number,\"image_path\": image_path,\"caption\": caption_text,\"scanpath\": scanpath})\n",
    "            print(video_data[video_id])\n",
    "\n",
    "frame_with_scanpath(source_scanpaths_dir, frame_directory, CaptionData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmpas as visualization of scan-paths\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "source_scanpaths_dir = \"/media/scratch/Trauma_Detection/code/ScanDMM/demo/output/source_scanpaths_csv_initial\"\n",
    "frame_directory = \"/media/scratch/datasets/WEB360/videos_512x1024x100/Frames/\"\n",
    "caption_path = \"/media/scratch/datasets/WEB360/WEB360_360TF_train.csv\"\n",
    "\n",
    "CaptionData = pd.read_csv(caption_path)\n",
    "CaptionData = CaptionData[CaptionData['videoid'].astype(str).isin(os.listdir(frame_directory))]\n",
    "\n",
    "def load_scanpath(scanpath_dir, frame_number):\n",
    "    frame_csv_path = os.path.join(scanpath_dir, f\"Frame_{frame_number}.csv\")\n",
    "    if not os.path.exists(frame_csv_path):\n",
    "        return None, frame_csv_path\n",
    "    df = pd.read_csv(frame_csv_path)\n",
    "    return df[['x', 'y']].values.tolist(), frame_csv_path\n",
    "\n",
    "def plot_single_scanpath_on_image(scanpath, img_path, save_path=None, caption=None, img_height=256, img_width=512):\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    normalized = all(0 <= x <= 1 and 0 <= y <= 1 for x, y in scanpath)\n",
    "    points_x = [(p[0] * img_width if normalized else p[0]) for p in scanpath]\n",
    "    points_y = [(p[1] * img_height if normalized else p[1]) for p in scanpath]\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(scanpath)))\n",
    "\n",
    "    previous_point = None\n",
    "    for idx, (x, y, c) in enumerate(zip(points_x, points_y, colors)):\n",
    "        if previous_point is not None:\n",
    "            if abs(previous_point[0] - x) < (img_width / 2):\n",
    "                ax.plot([previous_point[0], x], [previous_point[1], y], color='blue', linewidth=2, alpha=0.4)\n",
    "            else:\n",
    "                h_diff = (y - previous_point[1]) / 2\n",
    "                if x > previous_point[0]:\n",
    "                    ax.plot([previous_point[0], 0], [previous_point[1], previous_point[1] + h_diff],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                    ax.plot([img_width, x], [previous_point[1] + h_diff, y],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                else:\n",
    "                    ax.plot([previous_point[0], img_width], [previous_point[1], previous_point[1] + h_diff],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                    ax.plot([0, x], [previous_point[1] + h_diff, y],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "        previous_point = (x, y)\n",
    "        ax.plot(x, y, marker='o', markersize=8, color=c, alpha=0.9)\n",
    "        ax.text(x + 4, y - 4, str(idx + 1), color='yellow', fontsize=9)\n",
    "    plt.figtext(0.5, 0.01, f\"📜 {caption}\", wrap=True, ha='center', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def frame_with_scanpath(source_scanpaths_dir, frame_directory, caption_df):\n",
    "    video_data={}\n",
    "    for video_id in sorted(os.listdir(frame_directory)):\n",
    "        video_data[video_id] =[]\n",
    "        video_frame_dir = os.path.join(frame_directory, video_id)\n",
    "        scanpath_video_dir = os.path.join(source_scanpaths_dir, video_id)\n",
    "        caption_row = caption_df[caption_df['videoid'].astype(str) == video_id]\n",
    "        caption_text = caption_row['name'].values[0] if not caption_row.empty else None\n",
    "\n",
    "        print(f\"\\n🎞️ Video: {video_id}\")\n",
    "        frame_files = sorted([f for f in os.listdir(video_frame_dir) if f.lower().endswith('.png')])\n",
    "        for frame_file in frame_files:\n",
    "            frame_number = int(re.search(r'frame_(\\d+)', frame_file).group(1).lstrip('0') or '0')\n",
    "            print(f\"  Frame: {frame_file} (Number: {frame_number})\")\n",
    "            image_path = os.path.join(video_frame_dir, frame_file)\n",
    "            scanpath, csv_path = load_scanpath(scanpath_video_dir, frame_number)\n",
    "            print(f\"  Frame Path : {image_path};  Scanpath CSV: {csv_path}\")\n",
    "            if scanpath is None:\n",
    "                continue\n",
    "            #plot_single_scanpath_on_image(scanpath, image_path, caption=caption_text)\n",
    "            video_data[video_id].append({\"frame_file\": frame_file,\"frame_number\": frame_number,\"image_path\": image_path,\"caption\": caption_text,\"scanpath\": scanpath})\n",
    "            print(video_data[video_id])\n",
    "\n",
    "frame_with_scanpath(source_scanpaths_dir, frame_directory, CaptionData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e59daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "source_scanpaths_dir = \"/home/nagasaithadishetty/scan_path_guided_diffusion/data/WEB360/videos/source_scanpaths\"\n",
    "frame_directory = \"/home/nagasaithadishetty/scan_path_guided_diffusion/data/WEB360/videos/Frames\"\n",
    "caption_path = \"/home/nagasaithadishetty/scan_path_guided_diffusion/data/WEB360/WEB360_360TF_train.csv\"\n",
    "output_root = \"/home/nagasaithadishetty/scan_path_guided_diffusion/data/WEB360/videos/Scanpath_images\"\n",
    "\n",
    "CaptionData = pd.read_csv(caption_path)\n",
    "CaptionData = CaptionData[CaptionData['videoid'].astype(str).isin(os.listdir(frame_directory))]\n",
    "\n",
    "def load_scanpath(scanpath_dir, frame_number):\n",
    "    frame_csv_path = os.path.join(scanpath_dir, f\"Frame_{frame_number}.csv\")\n",
    "    if not os.path.exists(frame_csv_path):\n",
    "        return None, frame_csv_path\n",
    "    df = pd.read_csv(frame_csv_path)\n",
    "    if {'y', 'x'}.issubset(df.columns):\n",
    "        return df[['y', 'x']].values.tolist(), frame_csv_path\n",
    "    else:\n",
    "        return df.values.tolist(), frame_csv_path\n",
    "\n",
    "def plot_single_scanpath_on_image(scanpath, img_path, save_path=None, caption=None, img_height=256, img_width=512):\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    normalized = all(0 <= x <= 1 and 0 <= y <= 1 for x, y in scanpath)\n",
    "    points_x = [(p[0] * img_width if normalized else p[0]) for p in scanpath]\n",
    "    points_y = [(p[1] * img_height if normalized else p[1]) for p in scanpath]\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(scanpath)))\n",
    "\n",
    "    previous_point = None\n",
    "    for idx, (x, y, c) in enumerate(zip(points_x, points_y, colors)):\n",
    "        if previous_point is not None:\n",
    "            if abs(previous_point[0] - x) < (img_width / 2):\n",
    "                ax.plot([previous_point[0], x], [previous_point[1], y], color='blue', linewidth=2, alpha=0.4)\n",
    "            else:\n",
    "                h_diff = (y - previous_point[1]) / 2\n",
    "                if x > previous_point[0]:\n",
    "                    ax.plot([previous_point[0], 0], [previous_point[1], previous_point[1] + h_diff],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                    ax.plot([img_width, x], [previous_point[1] + h_diff, y],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                else:\n",
    "                    ax.plot([previous_point[0], img_width], [previous_point[1], previous_point[1] + h_diff],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "                    ax.plot([0, x], [previous_point[1] + h_diff, y],\n",
    "                            color='blue', linewidth=2, alpha=0.4)\n",
    "        previous_point = (x, y)\n",
    "        ax.plot(x, y, marker='o', markersize=8, color=c, alpha=0.9)\n",
    "        ax.text(x + 4, y - 4, str(idx + 1), color='yellow', fontsize=9)\n",
    "\n",
    "    if caption:\n",
    "        plt.figtext(0.5, 0.01, f\"{caption}\", wrap=True, ha='center', fontsize=10)\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)  \n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def frame_with_scanpath(source_scanpaths_dir, frame_directory, caption_df, output_root):\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    for video_id in sorted(os.listdir(frame_directory)):\n",
    "        video_frame_dir = os.path.join(frame_directory, video_id)\n",
    "        if not os.path.isdir(video_frame_dir):\n",
    "            continue  \n",
    "\n",
    "        scanpath_video_dir = os.path.join(source_scanpaths_dir, video_id)\n",
    "        caption_row = caption_df[caption_df['videoid'].astype(str) == video_id]\n",
    "        caption_text = caption_row['name'].values[0] if not caption_row.empty else None\n",
    "\n",
    "        print(f\"\\n🎞️ Processing Video: {video_id}\")\n",
    "        frame_files = sorted([f for f in os.listdir(video_frame_dir) if f.lower().endswith('.png')],\n",
    "                             key=lambda x: int(re.search(r'(\\d+)', x).group(1)))\n",
    "        save_dir = os.path.join(output_root, video_id)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        for frame_file in frame_files:\n",
    "            frame_number = int(re.search(r'(\\d+)', frame_file).group(1))\n",
    "            image_path = os.path.join(video_frame_dir, frame_file)\n",
    "            scanpath, csv_path = load_scanpath(scanpath_video_dir, frame_number)\n",
    "            if scanpath is None:\n",
    "                continue\n",
    "            save_path = os.path.join(save_dir, frame_file)\n",
    "            #plot_single_scanpath_on_image(scanpath, image_path, save_path=save_path, caption=caption_text)\n",
    "            print(f\"  Frame: {frame_file} → Saved at {save_path}\")\n",
    "frame_with_scanpath(source_scanpaths_dir, frame_directory, CaptionData, output_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaf23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_heatmaps(image_root, scanpath_root, output_root, sigma=50):\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    for video_name in sorted(os.listdir(image_root)):\n",
    "        video_path = os.path.join(image_root, video_name)\n",
    "        scan_path = os.path.join(scanpath_root, video_name)\n",
    "\n",
    "        if not os.path.isdir(video_path) or not os.path.isdir(scan_path):\n",
    "            continue\n",
    "        video_output_dir = os.path.join(output_root, video_name)\n",
    "        heatmap_dir = os.path.join(video_output_dir, \"heatmaps\")\n",
    "        overlay_dir = os.path.join(video_output_dir, \"overlay\")\n",
    "        os.makedirs(heatmap_dir, exist_ok=True)\n",
    "        os.makedirs(overlay_dir, exist_ok=True)\n",
    "\n",
    "        frame_files = [f for f in os.listdir(video_path) if f.endswith('.png')]\n",
    "        frame_files.sort(key=lambda x: int(re.search(r'(\\d+)', x).group(1)))\n",
    "\n",
    "        for frame_file in frame_files:\n",
    "            if not frame_file.endswith(\".png\"):\n",
    "                continue\n",
    "\n",
    "            frame_num = os.path.splitext(frame_file)[0]\n",
    "            img_path = os.path.join(video_path, frame_file)\n",
    "            csv_path = os.path.join(scan_path, f\"frame_{frame_num}.csv\")\n",
    "\n",
    "            if not os.path.exists(csv_path):\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            h, w = img.shape[:2]\n",
    "\n",
    "            try:\n",
    "                df_coords = pd.read_csv(csv_path)\n",
    "                if {'y', 'x'}.issubset(df_coords.columns):\n",
    "                    coords = df_coords[['y', 'x']].values\n",
    "                else:\n",
    "                    coords = df_coords.values\n",
    "            except Exception:\n",
    "                print(f\"Error reading {csv_path}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            valid_coords = []\n",
    "            for row in coords:\n",
    "                try:\n",
    "                    y, x = float(row[0]), float(row[1])\n",
    "                    valid_coords.append((int(y * h), int(x * w)))\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            heatmap = np.zeros((h, w), dtype=np.float32)\n",
    "            for y, x in valid_coords:\n",
    "                if 0 <= y < h and 0 <= x < w:\n",
    "                    heatmap[y, x] += 1\n",
    "\n",
    "            heatmap = cv2.GaussianBlur(heatmap, (0, 0), sigma)\n",
    "            heatmap_norm = heatmap / heatmap.max() if heatmap.max() > 0 else heatmap\n",
    "            heatmap_uint8 = (heatmap_norm * 255).astype(np.uint8)\n",
    "\n",
    "            heatmap_file = os.path.join(heatmap_dir, f\"{frame_num}.png\")\n",
    "            cv2.imwrite(heatmap_file, heatmap_uint8)\n",
    "            heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "            overlay = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
    "            overlay_file = os.path.join(overlay_dir, f\"{frame_num}.png\")\n",
    "            cv2.imwrite(overlay_file, overlay)\n",
    "\n",
    "            print(f\"Saved: Heatmap → {heatmap_file}, Overlay → {overlay_file}\")\n",
    "\n",
    "generate_heatmaps(\n",
    "    image_root=\"/home/nagasaithadishetty/scan_path_guided_diffusion/data/WEB360/videos/Frames\",\n",
    "    scanpath_root=\"/home/nagasaithadishetty/scan_path_guided_diffusion/data/WEB360/videos/source_scanpaths\",\n",
    "    output_root=\"/home/nagasaithadishetty/scan_path_guided_diffusion/data/WEB360/videos/heat_maps_organized\",\n",
    "    sigma=80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
